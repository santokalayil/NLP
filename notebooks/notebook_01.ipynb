{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "- BERT - can be used. Free model - we need to tranfer learning - to use on our own use cases\n",
    "- GPP3 - Free to use now - by OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique1: Rules & Heuristics - Regular Expressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching patterns in a text and getting the information\n",
    "import re, regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "website: regex101.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique2: Machine Learning (Statistical Method): Spam Detection using Count Vectorizer and Naive Bayes ML technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TB;\n",
    "    A[Raw Text] --> B[Count Vectorizer - conversion into number]\n",
    "    B --> C{Naive Bayes Classifier} --> S[Spam] & NS[Non Spam]\n",
    "```\n",
    "\n",
    "- CodeBasics has a video on Naive Bayes (the second video in which he talks about it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally on raw text we do some preprocesing techniques like lemmatization, removing punctuations, TF IDF Vectorization technique, \n",
    "\n",
    "Problem with simple count vectorization, - traning samples - if new input text is not seen by training model, then it iwll fail\n",
    "\n",
    "So there is another method - called \"Sentence Embeddings - Deep Learning techinique\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique3: Sentence Embedding - Deep Learning Method\n",
    "\n",
    "```mermaid\n",
    "graph TB;\n",
    "    raw_text[hurry up for an offer to win cash] --> sentence_embedding[Sentence Embeddings] --> numbers[[5, 9, 10, 0, 0...., 6]]\n",
    "    raw_text1[rush for tis great deal to win money] --> sentence_embedding1[Sentence Embeddings] --> numbers1[[5.1, 9, 10, 0.3, 1, ....., 6]]\n",
    "\n",
    "    numbers -.coasine similarity.- numbers1\n",
    "    numbers & numbers1 --> NB{Naive Bayes Classifier}\n",
    "    NB --> Spam & NonSpam\n",
    "```\n",
    "Use these number vectors to Naive bayes classifer, it will produce more accurate spam detction - This is not affected by Unseen sentences in the training phase\n",
    "\n",
    "\n",
    "\n",
    "BERT - Google's Transformer model which can be used  to generate **Sentence Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face - Sentence tranformers\n",
    "Google it. we will reach the page. We can see for demo. Those sentence comparsion methods are based on sentence embeddings DL technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp--9r02_gx-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
